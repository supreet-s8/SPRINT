#!/usr/bin/env python
 
import time
import datetime
import logging
import os, sys, shutil
 
try:
    import pexpect
except ImportError:
    print "Failed to import pexpect module"
    sys.exit(1)

try:
    from setproctitle import setproctitle
except ImportError:
    setproctitle = None

from daemon import Daemon

__all__ = ['Server']

# Global variables
dirslug = "total 123\r\n-rw-r--r--  1 user  group  12345 Jan  1 00:00 DUMMY.file\r\n"
sftp_timeout = 300

def fatal(msg):
    """Report a fatal error to STDOUT"""
    logging.critical(msg)
    print "FATAL: %s" % msg
    sys.exit(1)

def file_cleanup(files):
    """Remove files if they exist.  Can accept a single file or a list of files."""
    if type(files) == type(str()):
        filelist = [files]
    elif type(files) == type(list()):
        filelist = files
    for file in filelist:
        if os.path.exists(file):
            os.remove(file)
            logging.debug("Removed file " + file)

        
def argmatey(args):
    """Parse stdin into argparse namespace object"""
    import argparse
    localpath = os.getcwd()
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=False)
    group.add_argument('--restart', dest='restart', action='store_true', help='restart a running daemon', default=False)
    group.add_argument('--stop', dest='stop', action='store_true', help='stop a running daemon', default=False)

    parser.add_argument('--remotetarget', dest='remotetargets', metavar='STRING', action='append', help='REQUIRED. String in user:pass@hostorip:/path/to/remoteside format (Can invoke multiple instances of this arg)', default=[], required=True)
    parser.add_argument('-d', '--debug', dest='debug', action='store_true', help='debug mode', default=False)
    parser.add_argument('--localdir', dest='localdir', help='REQUIRED. Local file directory.', default=None, required=True)
    parser.add_argument('--includeip', dest='includeips', metavar='IP', action='append', help='Full or partial IP address expected at beginning of filenames to include, e.g. --includeip 10.26.56 would match and include files like 10.26.56.64_filename.csv.gz (Can invoke multiple instances of this arg)', default=[])
    parser.add_argument('--excludeip', dest='excludeips', metavar='IP', action='append', help='Full or partial IP address expected at beginning of filenames to exclude, e.g. --excludeip 10.26.56 would match and exclude files like 10.26.56.64_filename.csv.gz (Can invoke multiple instances of this arg)', default=[])
    parser.add_argument('--includestr', dest='includestr', metavar='STRING', action='append', help='Include files with matching string in filename. Can invoke multiple instances of this arg. (If not specified, defaults to this list: ["HTTP", "GENERIC", "EMAIL", "FTP_DATA"])', default=['HTTP','GENERIC','EMAIL','FTP_DATA'])
    parser.add_argument('--excludestr', dest='excludestr', metavar='STRING', action='append', help='Exclude files with matching string in filename. Can invoke multiple instances of this arg.', default=[])
    parser.add_argument('-s', '--sleep-interval', dest='sleep_interval', help='interval between attempts to upload', type=int, default=10)
    parser.add_argument('-l', dest='log_file', help='log file', type=str, default=None)
    parser.add_argument('-D', '--daemon', dest='daemonize', action='store_true', help='daemonize', default=False)
    parser.add_argument('--pidfile', dest='pidfile', action='store', help='pid file', default='/tmp/NSmediate.pid')
    parser.add_argument('--lockfile', dest='lockfile', action='store', help='lock file', default='/tmp/NSmediate.lck')

    retval = parser.parse_args(args)    
    return retval
    
    
def process_targets(targets):
    """Process a list of potential targets."""
    fail = False
    results = {}
    for t in targets:
        try:
            tmeta = t.split('@')
        except:
            logging.critical("Argument misconfiguration for remotetarget: %s" % t)
            fail = True
        if len(tmeta) == 2:                                         # Must have 2 args here
            if len(tmeta[1].split(':')) == 2:                       #  Must have 2 args here, too
                host = tmeta[1].split(':')[0]                       #   Define host
                if host in results:                                   #   This means a duplicate...
                    logging.critical("Duplicate host found in configuration: " + host + ", in remote target list: %s" % options.remotetargets)
                    fail = True
                results[host] = {}                                  #   define host key as dict 
                results[host]['path'] = tmeta[1].split(':')[1]      #   define key 'path' in dict
                if len(tmeta[0].split(':')) == 2 :                  #   May have 2 args here, if we do:
                    results[host]['user'] = tmeta[0].split(':')[0]  #     Define key 'user'
                    results[host]['pass'] = tmeta[0].split(':')[1]  #     Define key 'pass'
                elif len(tmeta[0].split(':')) == 1 :                #   If we only have 1 arg here:
                    results[host]['user'] = tmeta[0].split(':')[0]  #     Presume first is key 'user'
                    results[host]['pass'] = 'NONE'                  #     Define key 'pass' as NONE
                else:
                    logging.critical("Argument misconfiguration with user/pass definition: %s" % tmeta[0])
                    fail = True
            else:
                logging.critical("Argument misconfiguration with host/path definition: %s" % tmeta[1])
                fail = True
    if fail:
        results = False
    return results

def test_targets(hostd, options):
    """Run ssh connection test against each host in host dictionary hostd"""
    retval = False                                  # Pre-set retval to False
    baddir = {'directory': 'No'}
    counter = 0                                     # Initialize counter to zero
    for host in hostd.iterkeys():                   # Loop through all hosts in dictionary
        sftptest           = options                #  Since we need most of the settings here, we copy it
        sftptest.user      = hostd[host]['user']    #  Reassign user
        sftptest.password  = hostd[host]['pass']    #  Reassign password
        sftptest.remotedir = hostd[host]['path']    #  Reassign path
        conn = SFTP(host, sftptest)                 #  Create connection object
        if conn.sftp_login():                       #  Initial login/password test.
            logging.debug("Good sftp connection to host %s" % host)
            rfiles = conn.get_remotefiles()         #  Test remote directory
            if rfiles == baddir:                    #  Check for {'directory': 'No'}
                logging.critical('Remote path ' + options.remotedir + ' does not exist on ' + host)
            else:
                conn.sftp_logout()              #   Logout just in case.
                counter += 1                    #   Increment counter
        else:                                       #  The connection was bad, log it
            logging.error("Unable to establish sftp connection to host %s and path %s" % (host, hostd[host]['path']))
    if counter == len(hostd):                       # We have success from each host
        retval = True                               #  Set return value to True
    return retval


def preparse(lines):
    """
    Pre-parse lines of output to strip undesired bits:
    ### $ ls -l
    ### total 48
    ### -rw-r--r-- 1 user group 12345 Jan  1 20:03 file1.txt
    ### -rw-r--r-- 1 user group 54321 Jan  1 20:24 file2.txt
    or
    ### sftp> put -p victory444.png
    ### Uploading victory444.png to /root/remote-dest/victory444.png
    ### victory444.png                  100%   21KB  21.2KB/s   00:00
    """
    try:
        retval = lines.split('\r\n')	# Split on newlines
        retval.pop(0) 			# Delete the previous "sendline"
        retval.pop() 			# Delete the last empty list item (leftover from last newline)
        # This leaves us with a list that looks like this:
        # ['-rw-r--r-- 1 user group 12345 Jan  1 20:03 file1.txt', '-rw-r--r-- 1 user group 54321 Jan  1 20:24 file2.txt']
        # or
        # ['victory444.png                  100%   21KB  21.2KB/s   00:00']
    except:
        logging.error("failed to preparse lines: %s" % lines)
    return retval


def parse_response(response, ptype):
    """Take output from sftp and parse.  Returns boolean"""
    # Pre-parse
    r = preparse(response)		# Pre-parse the response
    # Copy
    if ptype == "copy":			#
        retval = False			# Set return value to False first
        if len(r) > 0: 			# Don't bother if empty result set
            for line in r:		# Scan each line
                if "100%" in line:	# Look for the string "100%"
                    retval = True	# Return value is true if it is
    # Rename
    if ptype == "rename":		# 
        retval = True			# Return value here is True first
        if len(r) > 0: 			# In this case, it's bad to have any size list
            retval = False		# Fail if we saw anything at all
            logging.error("Error found: %s" " ".join(r)) # and report
    return retval

def lstrim(response):
    """Take ls -l output from sftp and turn it into a dict of {filename,size}"""
    retval = {}
    ls = preparse(response)		# Pre-parse the response
    if len(ls) > 0:                     # Don't bother if empty result set
        for line in ls:			# Iterate over all lines
            if len(line.split()) > 7:   # Only process lines that have 8 columns
                f = line.split()[8]	# Column 9 is the filename (0..8)
                s = line.split()[4]	# Column 5 is the file size (0..4)
                retval[f] = s		# retval is a dictionary of {f:s}
    return retval


def filechk(lfiles, rfiles):
    """
    Check local files against remote files.  Verify that file size matches.
    Check if remote file has tmp_ prepended
    Return list of files not yet copied.
    """
    retval = {}
    for lf in lfiles.iterkeys():			    # Iterate over all keys in dictionary
        tmprf = 'tmp_' + lf				        #  tmprf is temporary remote name of lf (local file)
        if not lf in rfiles and not tmprf in rfiles: # If the file isn't on the remote server (either completed or tmp_)
            retval[lf] = "copy" 			    #    then flag file as "to copy"
        elif tmprf in rfiles: 				    #   If the file is there but prepended with tmp_
            if lfiles[lf] == rfiles[tmprf]: 	#    and if the size of local & remote match:
                retval[lf] = "rename" 			#     then flag the file as "to rename"
            else:					            #    or else
                retval[lf] = "failed" 			#     if they don't match, it failed
        elif lf in rfiles:                      #   If the file already exists on the remote side
            if lfiles[lf] != rfiles[lf]: 		#   If the size of local & remote don't match:
                retval[lf] = "failed"    		#    mark it failed
            else:                               #   Otherwise
                retval[lf] = "completed"		#    they match, it's completed.
        else: 						            #   Otherwise:
            retval[lf] = "unknown"  			#     Something is wrong.
            logging.error("Unknown error.  Can't match local and remote sizes of " + lf)
    return retval

class SFTP(object):
    """This is where the sftp magic happens"""
    def __init__(self, host, options):
        """Initialize variables and constants"""
        # Variables
        self.host = host
        self.user = options.user
        self.password = options.password
        self.localdir = options.localdir
        self.remotedir = options.remotedir
        self.includeips = options.includeips
        self.excludeips = options.excludeips
        self.includestr = options.includestr
        self.excludestr = options.excludestr
        # Constants
        self.SFTP_PROMPT = 'sftp> ' ### This is way too simple for industrial use -- we will change is ASAP.
        self.TERMINAL_PROMPT = '(?i)terminal type\?'
        # This is the prompt we get if SSH does not have the remote host's public key stored in the cache.
        self.SSH_NEWKEY = '(?i)are you sure you want to continue connecting'

    def sftp_login(self):
        """Create and return a child instance"""
        retval = False
        # Login via SSH
        protochild = pexpect.spawn('sftp %s@%s'%(self.user, self.host), timeout=10)
        i = protochild.expect([pexpect.TIMEOUT, self.SSH_NEWKEY, self.SFTP_PROMPT, '(?i)password'])
        if i == 0: # Timeout
            logging.error('Could not login with SSH. Here is what SSH said: %s %s' % (protochild.before, protochild.after))
            logging.error(str(protochild))            
            # sys.exit (1) # We are daemonized here and built to repeat.  Just log and hope it reconnects
        if i == 1: # In this case SSH does not have the public key cached.
            protochild.sendline ('yes')
            protochild.expect ('(?i)password')
            logging.info('Adding SSH public key to cache...')
            retval = True            
        if i == 2:
            # This may happen if a public key was setup to automatically login.
            # But beware, the SFTP_PROMPT at this point is very trivial and
            # could be fooled by some output in the MOTD or login message.
            logging.debug('Login successful')
            retval = True
            pass
        if i == 3:
            protochild.sendline(self.password)
            # Now we are either at the command prompt or
            # the login process is asking for our terminal type.
            i = protochild.expect ([self.SFTP_PROMPT, self.TERMINAL_PROMPT, '(?i)password'])
            if i == 1:
                protochild.expect (self.SFTP_PROMPT)
            elif i == 2:
                logging.error("Password not accepted for %s@%s" % (self.user, self.host))
            else:
                logging.debug('Password accepted')
                retval = True
        self.child = protochild
        return retval

    def sftp_conn_check(self):
        """Send a simple CR/LF to test if the connection is up"""
        retval = False
        self.child.sendline ('')		# Send a CR/LF
        self.child.expect (self.SFTP_PROMPT)	# Hopefully get the SFTP_PROMPT
        response = self.child.after		# Check here
        if response != self.SFTP_PROMPT:	# If we do NOT get it
            self.sftp_logout()			# Just in case, we log out first. May be moot.
            self.child = sftp_login()		# Refresh self.child
            logging.warn("Connection reset.")
        else:
            #logging.debug("Connection okay.")
            retval = True
        return retval

    def sftp_logout(self):
        """Logout"""
        self.child.sendline ('bye')
        logging.debug("sftp logout")


    def cluded(self, iplist, stringlist, filedict, operation='include'):
        """
            Return only files INcluded or EXcluded (based on value of operation)
            by ips in iplist, and and by string(s) in stringlist
        """
        # IPs
        matching_files = {}					            # Zero out first dictionary
        if len(iplist) > 0:					            # Only run if there are entries in iplist
            for k,v in filedict.iteritems():		    #  Loop through all files
                match = False					        #   Initialize match to false
                for ip in iplist:				        #   Loop through all ips
                    if k.startswith(ip):			    #     If key (filename) "starts with" the ip
                        match = True				    #       set match to True
                if match and operation == 'include':    #   If we find a match and we're set to include
                    matching_files[k] = v			    #      add the matching entry to "matching_files" (include)
                elif not match and operation == 'exclude': #   If we find NO match and we're set to exclude
                    matching_files[k] = v			    #      add the matching entry to "matching_files" (not excluded)
        else:							                # No IPs provided for filter
            matching_files = filedict				    #  Pass all through

        # Strings
        resultdict = {}						            # Zero out the "final result" dictionary
        if len(stringlist) > 0:					        # Only run if there are entries in stringlist
            for k in matching_files:				    #  Loop through the files in our matches from the first set
                match = False					        #   Initialize match to false
                for string in stringlist:			    #   Loop through all strings in our include_strings
                    if string in k:				        #     if the string is in the key (filename)
                        match = True				    #       set match to True
                if match and operation == 'include':	#    If we find a match and we're set to include
                    resultdict[k] = matching_files[k]	#      add the matching entry to final result (include)
                elif not match and operation == 'exclude': #    If we find NO match and we're set to exclude
                    resultdict[k] = matching_files[k]	#      add the matching entry to final result (not excluded)
        else:							                # No Strings provided for filter
            resultdict = matching_files				    #  Pass all through
        return resultdict					            # return the final result


    def get_localfiles(self):
        """Get listing of local files"""
        llsraw = pexpect.run('ls -l ' + self.localdir)      # Capture local ls -l
        #logging.debug("Local dir: %s" % self.localdir)       
        #logging.debug("Local dir ls (raw): %s" % llsraw)
        if not llsraw:                                      # If it's empty
            llsraw = dirslug                                #  assign the "template"
        prefilter = lstrim(llsraw)                          # trim output to dict of {file, size} entries
        filtered = self.cluded(self.includeips, self.includestr, prefilter, operation='include')	# Filter out non-matching filenames
        self.lfiles = self.cluded(self.excludeips, self.excludestr, filtered, operation='exclude')	# Filter out matching filenames
        #logging.debug("Local files: %s" % self.lfiles)
        return self.lfiles


    def get_remotefiles(self):
        """Get listing of remote files"""
        self.sftp_conn_check()			                # Guarantee connectivity
        self.child.sendline ('ls -l ' + self.remotedir) # Run remote ls -l
        self.child.timeout = sftp_timeout               # Set the timeout
        self.child.expect (self.SFTP_PROMPT)	        # Expect the prompt
        rlsraw = self.child.before                      # capture raw output
        #logging.debug("Remote dir: %s" % self.remotedir)        
        #logging.debug("Remote dir ls (raw): %s" % rlsraw)                
        self.rfiles = lstrim(rlsraw)                    # trim output to dict of {file, size} entries
        #logging.debug("Remote files: %s" % self.rfiles)                
        return self.rfiles


    def check_duptmpfile(self, f):
        """Get listing of remote files"""
        dup = False
        self.sftp_conn_check()			                # Guarantee connectivity
        self.child.sendline ('ls -l ' + self.remotedir) # Run remote ls -l
        self.child.timeout = sftp_timeout               # Set the timeout
        self.child.expect (self.SFTP_PROMPT)	        # Expect the prompt
        rlsraw = self.child.before                      # capture raw output
        rfiles = lstrim(rlsraw)                         # trim output to dict of {file, size} entries
        if ("tmp_" + f) and f in rfiles.iterkeys():     # Check for condition where both tmp_ file and regular file exist
            if rfiles[f] == rfiles["tmp_" + f]:         #  If they have the same size
                logging.warn("Files tmp_" + f + " and " + f + " have same file size")
                self.sftp_rm(f)                         #   Delete the offender
                dup = True                              #   It is a duplicate
        return dup


    def sftp_rename(self, f):
        """Rename the file from tmp_f to just f"""
        retval = False                                  # Initialize to False
        self.sftp_conn_check()			                # Guarantee connectivity
        self.child.sendline ('rename ' + self.remotedir + '/tmp_' + f + ' ' + self.remotedir + '/' + f) # Rename the tmp_ file
        self.child.expect (self.SFTP_PROMPT)	        # Expect the prompt
        rename_resp_raw = self.child.before 	        # Get the response
        rename_success = parse_response(rename_resp_raw, "rename") # Parse for boolean result
        if rename_success:			                    # If True
            logging.info("COMPLETED: " + f + " copied to " + self.host) # Log completion
            retval = True                               #  Set retval to True
        elif self.check_duptmpfile(f):                  # Check if duplicate exists...
            logging.warn("Removed duplicate file " + f + " from " + self.host)
        else:
            logging.error("Unknown error in rename of file " + f + " on " + self.host)
        return retval


    def sftp_copy(self, f):
        """Copy, and if successful call the rename"""
        retval = False                                  # Initialize to False
        self.sftp_conn_check()                          # Guarantee connectivity
        lfile = self.localdir + "/" + f                 # Set to local path + filename
        rtmpfile = self.remotedir + "/tmp_" + f         # Set to remote path + "tmp_" + filename
        self.child.sendline ('put -p ' + lfile + ' ' + rtmpfile)    # Put the file to a tmp_ file
        self.child.timeout = sftp_timeout               # Set the timeout
        self.child.expect (self.SFTP_PROMPT)            # Expect the prompt
        copy_resp_raw = self.child.before               # Get the response
        #logging.debug('copy_resp_raw = %s' % copy_resp_raw)
        copy_success = parse_response(copy_resp_raw, "copy") # Parse for boolean result
        if copy_success:				                # If True
            logging.debug("File " + lfile + " successfully copied to " + rtmpfile + " on " + self.host) # Log success
            if self.sftp_rename(f):                     # Attempt to rename (checks for fails itself)
                retval = True                           # Set returnval to True.
        else:						     # Otherwise:
            logging.error("Unsuccessful file transfer: " + lfile + " to " + self.host) # Log failure
        return retval
            
            
    def sftp_rm(self, f):
        """Remove file f"""
        self.sftp_conn_check()			        # Guarantee connectivity
        logging.debug('Removing file: ' + f)	# Log removal
        self.child.sendline ('rm ' + f)		    # Remove file
        self.child.expect (self.SFTP_PROMPT)	#
        

    def do_sftp(self, dutydict, delete=False):
        """Run the commands against the current pexpect child"""
        fail = False
        retval = {}                             # Initialize empty return dictionary.
        for f in dutydict.iterkeys():			# Run against each file in the dict
            retval[f] = False                   # Mark each file False to begin with
            if dutydict[f] == "copy":			# For files marked "copy"
                logging.debug("Copying file " + f)
                if not self.sftp_copy(f):       #  Copy file
                    fail = True                 #   Mark failed if we don't get True
            elif dutydict[f] == "failed":		# For files marked "failed"
                logging.warn("Retrying failed download for " + f) # Log warning
                self.sftp_rm(f)				    #  Remove old copy first
                if not self.sftp_copy(f):       #  Re-copy file
                    fail = True                 #   Mark failed if we don't get True
            elif dutydict[f] == "rename":		# For files marked "rename"
                logging.debug("Renaming file tmp_" + f + " to " + f) # Log rename
                self.sftp_rename(f)			    #  Rename file
            elif dutydict[f] == "completed":    # If the file is successfully copied
                retval[f] = True                #  Set the return value for this file to True
            elif delete: 					    # If delete is True:
                if dutydict[f] == "completed":  #  If it copied successfully
                    try:
                        os.remove(localdir + "/" + f) # Remove the file locally
                        logging.debug("Deleting successfully copied file: " + f)
                    except:
                        logging.error("Unable to delete successfully copied file " + f)
        return retval                           # Return the dictionary
                        

class Server(object):
    """This is where the daemon dwells, with all his underlings"""
    def __init__(self, options):
        """Initialize variables and constants"""
        # Variables
        self.options        = options
        self.sleep_interval = options.sleep_interval
        self.daemonize      = options.daemonize
        self.localdir       = options.localdir
        self.debug          = options.debug


    def process(self):
        """The meat of the operation"""
        hostd = self.options.hostd
        logging.debug("Remote host list: %s" % hostd.keys())
        resultdict = {}
        for host in hostd.iterkeys():
            sftpconn           = self.options           # Since we need most of the settings here, we copy it
            sftpconn.user      = hostd[host]['user']    # Reassign user
            sftpconn.password  = hostd[host]['pass']    # Reassign password
            sftpconn.remotedir = hostd[host]['path']    # Reassign path
            logging.debug("Remote host: %s" % host)
            conn = SFTP(host, sftpconn)
            conn.sftp_login()	                        # Initial login
            lfiles = conn.get_localfiles()		        # Get list of local files
            rfiles = conn.get_remotefiles()		        # Get list of remote files
            dutydict = filechk(lfiles, rfiles)          # Obtain duty roster for each file (copy, rename, failed, completed)
            results = conn.do_sftp(dutydict)            # Do the actual sftp stuff.
            resultdict[host] = results                  # Append the results
            conn.sftp_logout()                          # Logout when done
        filelist = []                                   # Initialize empty file list
        for host in hostd.iterkeys():                   # Loop through host keys
            for file in resultdict[host].iterkeys():    #  Loop through files
                filelist.append(file)                   #   Add all files to filelist
        files = set(filelist)                           # Unique-ify the filelist
        logging.debug("Files: %s" % files)
        for file in files:                              # Loop through all files
            counter = 0                                 #  Set counter to 0
            for host in hostd.iterkeys():               #  Loop through all host keys
                if file in resultdict[host].iterkeys(): #   Check to see if file is in sub-dict for host
                    counter += 1                        #    If it is, increment counter
            if counter == len(hostd):                   #   Check to see if the count is same as number of hosts 
                                                        #   (e.g. one file per host, successfully copied)
                try:                                    #    If it is, try to remove the local file
                    os.remove(self.localdir + "/" + file) # Remove the file locally
                    logging.debug("Deleting successfully copied file: " + file)
                except:                                 #    Otherwise log the failure
                    logging.error("Unable to delete successfully copied file " + file)
                

    def serve(self):
        """The actual daemon process lives here"""
        import signal
        import sys
        def signal_handler(signal, frame):
            """Need this for the signal caller, even though we don't really use it"""
            self.stop()
        signal.signal(signal.SIGINT, signal_handler)
        if self.daemonize:
            while 1:
                logging.debug('Cycle started...')
                self.process()					# Run the full process
                logging.debug('Cycle completed.')
                time.sleep(self.sleep_interval)			# Pause for the sleep interval
        else:
            logging.debug('Cycle started...')
            self.process()					# Run the full process
            logging.debug('Cycle completed.')
            

    def stop(self):
        """Dummy process here for when signal_handler calls it"""
        pass


class ServerDaemon(Daemon):
    """ServerDaemon object class"""
    def run(self, options):
        """Set the process to run"""
        if setproctitle:
            setproctitle('NSmediator')
        server = Server(options)
        server.serve()
    
def main():
    """Do I have to describe what main does?"""
    # Get options
    options = argmatey(sys.argv[1:])
    log_file = options.log_file if options.log_file else 'STDERR'

    # Setup logging
    logging.basicConfig(level=logging.DEBUG if options.debug else logging.INFO,
                        format='%(asctime)s %(levelname)-9s %(funcName)18s:%(lineno)-4d %(message)s',
                        datefmt="%Y-%m-%dT%H:%M:%S%z",
                        stream=open(options.log_file, 'a') if options.log_file else sys.stderr)
    logging.info("Job starting...")

    # Check if lockfile is pre-existent
    if os.path.exists(options.lockfile):
        now = int(time.time())
        if now - os.path.getmtime(options.lockfile) > 1800:
            os.remove(options.lockfile)
            logging.warn("Age of lockfile exceeded 30 minutes. Deleted Lockfile.")
        else:
            fatal("Lockfile exists.  Please delete, or verify no other instance running.")

    # Create lockfile
    with open(options.lockfile, 'w') as lockfile:
        lockfile.write("locked")
    logging.debug("Created lock file " + options.lockfile)

    # Test localdir to see if it's good
    if not os.path.exists(options.localdir):
        file_cleanup(options.lockfile)      # Clean up the file afterward
        fatal("Local path " + options.localdir + " does not exist!")
        
    # Test whether the connections given will work.  All must work or the script will fail.
    logging.info("Testing sftp connections...")
    hostd = {}                              # Initialize empty dictionary
    # Break down user:pass@hostorip:/path/to/remoteside format into a dictionary
    hostd = process_targets(options.remotetargets)
    if not hostd:                           # If we didn't find a host, that's a problem
        file_cleanup(options.lockfile)      # Clean up the file afterward
        fatal("No hosts found.  Exiting.")

    if not test_targets(hostd, options):    # Will return True if all hosts are reachable.
        file_cleanup(options.lockfile)      # Clean up the file afterward
        fatal("Failed to connect to one or more hosts.  Check log entries in %s" % log_file)
    else:
        logging.info("sftp connection testing completed successfully.")
    
    # Having verified each host in hostd, we add it to options now
    options.hostd = hostd

    # Begin the real work
    logging.info("Starting main processes...")
    daemon = ServerDaemon(options.pidfile)  # Since we have the option to daemonize, set it up
    if options.daemonize:                   # If we're daemonizing
        daemon.start(options)               #  start with those options
    elif options.restart:                   # If we get the command to restart
        daemon.restart(options)             #  do the restart
    elif options.stop:                      # If we get the command to stop
        daemon.stop()                       #  stop the daemon
    else:                                   # Otherwise
        daemon.run(options)                 #  Run once with the options

    file_cleanup([options.pidfile, options.lockfile])   # Cleanup the files afterwards
    logging.info("Job completed.")
        
if __name__ == '__main__':
    main()
